{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 10,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mad_outlier(y, thresh):\n",
    "    '''\n",
    "    compute outliers based on mad\n",
    "    # args\n",
    "        y: assumed to be array with shape (N,1)\n",
    "        thresh: float()\n",
    "    # returns\n",
    "        array index of outliers\n",
    "    '''\n",
    "    y = np.expand_dims(y, axis=1)\n",
    "    median = np.median(y)\n",
    "    diff = np.sum((y - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "    return modified_z_score > thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IVE_tickbidask.txt', delimiter = \",\", names = ['date', 'time', 'price', 'bid', 'ask', 'vol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = mad_outlier(df.price.values, 2.57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### drop the incorrect rows\n",
    "check = df.loc[~mad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = check\n",
    "df['Datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "df = df.set_index('Datetime')\n",
    "df = df.drop(['date','time'], axis=1)\n",
    "df['dollar_vol'] = df.price * df.vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def dollar_bars(df, dv_column, m):\n",
    "    '''\n",
    "    compute dollar bars\n",
    "    # args\n",
    "        df: pd.DataFrame()\n",
    "        column: name for dollar volume data\n",
    "        m: int(), threshold value for dollars\n",
    "    # returns\n",
    "        idx: list of indices\n",
    "    '''\n",
    "    t = df[dv_column]\n",
    "    ts = 0\n",
    "    idx = []\n",
    "    for i, x in enumerate(tqdm(t)):\n",
    "        ts += x\n",
    "        if ts >= m:\n",
    "            idx.append(i)\n",
    "            ts = 0\n",
    "            continue\n",
    "    return idx\n",
    "\n",
    "def dollar_bar_df(df, dv_column, m):\n",
    "    idx = dollar_bars(df, dv_column, m)\n",
    "    return df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbars = dollar_bar_df(df, 'dollar_vol', 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDailyVol(close,\n",
    "                span0=100):\n",
    "    \"\"\"SNIPPET 3.1 DAILY VOLATILITY ESTIMATES\n",
    "    Daily vol reindexed to close\n",
    "    \"\"\" \n",
    "    df0=close.index.searchsorted(close.index-pd.Timedelta(days=1))\n",
    "    df0=df0[df0>0]   \n",
    "    df0=(pd.Series(close.index[df0-1], \n",
    "                   index=close.index[close.shape[0]-df0.shape[0]:]))   \n",
    "    try:\n",
    "        df0=close.loc[df0.index]/close.loc[df0.values].values-1 # daily rets\n",
    "    except Exception as e:\n",
    "        print(f'error: {e}\\nplease confirm no duplicate indices')\n",
    "    df0=df0.ewm(span=span0).std().rename('dailyVol')\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = dbars.price.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = close.drop_duplicates()\n",
    "close = close[~close.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyVol = getDailyVol(close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots()\n",
    "dailyVol.plot(ax=ax)\n",
    "ax.axhline(dailyVol.mean(),ls='--',color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTEvents(gRaw, h):\n",
    "    tEvents, sPos, sNeg = [], 0, 0\n",
    "    diff = np.log(gRaw).diff().dropna()\n",
    "    for i in tqdm(diff.index[1:]):\n",
    "        try:\n",
    "            pos, neg = float(sPos+diff.loc[i]), float(sNeg+diff.loc[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(sPos+diff.loc[i], type(sPos+diff.loc[i]))\n",
    "            print(sNeg+diff.loc[i], type(sNeg+diff.loc[i]))\n",
    "            break\n",
    "        sPos, sNeg=max(0., pos), min(0., neg)\n",
    "        if sNeg<-h:\n",
    "            sNeg=0;tEvents.append(i)\n",
    "        elif sPos>h:\n",
    "            sPos=0;tEvents.append(i)\n",
    "    return pd.DatetimeIndex(tEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tEvents = getTEvents(close, h=dailyVol.mean())\n",
    "tEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addVerticalBarrier(tEvents, close, numDays=1):\n",
    "    t1=close.index.searchsorted(tEvents+pd.Timedelta(days=numDays))\n",
    "    t1=t1[t1<close.shape[0]]\n",
    "    t1=(pd.Series(close.index[t1],index=tEvents[:t1.shape[0]]))\n",
    "    return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = addVerticalBarrier(tEvents, close, numDays=1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvents(close, tEvents, ptSl, trgt, minRet, numThreads, t1=False, side=None):\n",
    "    #1) get target\n",
    "    trgt=trgt.loc[trgt.index.intersection(tEvents)]\n",
    "    trgt=trgt[trgt>minRet] # minRet\n",
    "    #2) get t1 (max holding period)\n",
    "    if t1 is False:t1=pd.Series(pd.NaT, index=tEvents)\n",
    "    #3) form events object, apply stop loss on t1\n",
    "    if side is None:side_,ptSl_=pd.Series(1.,index=trgt.index), [ptSl[0],ptSl[0]]\n",
    "    else: side_,ptSl_=side.loc[side.index.intersection(trgt.index)],ptSl[:2]\n",
    "    events=(pd.concat({'t1':t1,'trgt':trgt,'side':side_}, axis=1)\n",
    "            .dropna(subset=['trgt']))\n",
    "    df0=mpPandasObj(func=applyPtSlOnT1,pdObj=('molecule',events.index),\n",
    "                    numThreads=numThreads,close=close,events=events,\n",
    "                    ptSl=ptSl_)\n",
    "    events['t1']=df0.dropna(how='all').min(axis=1) # pd.min ignores nan\n",
    "    if side is None:events=events.drop('side',axis=1)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpPandasObj(func,pdObj,numThreads=24,mpBatches=1,linMols=True,**kargs):\n",
    "    '''\n",
    "    Parallelize jobs, return a dataframe or series\n",
    "    + func: function to be parallelized. Returns a DataFrame\n",
    "    + pdObj[0]: Name of argument used to pass the molecule\n",
    "    + pdObj[1]: List of atoms that will be grouped into molecules\n",
    "    + kwds: any other argument needed by func\n",
    "    \n",
    "    Example: df1=mpPandasObj(func,('molecule',df0.index),24,**kwds)\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    #if linMols:parts=linParts(len(argList[1]),numThreads*mpBatches)\n",
    "    #else:parts=nestedParts(len(argList[1]),numThreads*mpBatches)\n",
    "    if linMols:parts=linParts(len(pdObj[1]),numThreads*mpBatches)\n",
    "    else:parts=nestedParts(len(pdObj[1]),numThreads*mpBatches)\n",
    "    \n",
    "    jobs=[]\n",
    "    for i in range(1,len(parts)):\n",
    "        job={pdObj[0]:pdObj[1][parts[i-1]:parts[i]],'func':func}\n",
    "        job.update(kargs)\n",
    "        jobs.append(job)\n",
    "    if numThreads==1:out=processJobs_(jobs)\n",
    "    else: out=processJobs(jobs,numThreads=numThreads)\n",
    "    if isinstance(out[0],pd.DataFrame):df0=pd.DataFrame()\n",
    "    elif isinstance(out[0],pd.Series):df0=pd.Series()\n",
    "    else:return out\n",
    "    for i in out:df0=df0.append(i)\n",
    "    df0=df0.sort_index()\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyPtSlOnT1(close,events,ptSl,molecule):\n",
    "    # apply stop loss/profit taking, if it takes place before t1 (end of event)\n",
    "    events_=events.loc[molecule]\n",
    "    out=events_[['t1']].copy(deep=True)\n",
    "    if ptSl[0]>0: pt=ptSl[0]*events_['trgt']\n",
    "    else: pt=pd.Series(index=events.index) # NaNs\n",
    "    if ptSl[1]>0: sl=-ptSl[1]*events_['trgt']\n",
    "    else: sl=pd.Series(index=events.index) # NaNs\n",
    "    for loc,t1 in events_['t1'].fillna(close.index[-1]).iteritems():\n",
    "        df0=close[loc:t1] # path prices\n",
    "        df0=(df0/close[loc]-1)*events_.at[loc,'side'] # path returns\n",
    "        out.loc[loc,'sl']=df0[df0<sl[loc]].index.min() # earliest stop loss\n",
    "        out.loc[loc,'pt']=df0[df0>pt[loc]].index.min() # earliest profit taking\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linParts(numAtoms,numThreads):\n",
    "    # partition of atoms with a single loop\n",
    "    parts=np.linspace(0,numAtoms,min(numThreads,numAtoms)+1)\n",
    "    parts=np.ceil(parts).astype(int)\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processJobs_(jobs):\n",
    "    # Run jobs sequentially, for debugging\n",
    "    out=[]\n",
    "    for job in jobs:\n",
    "        out_=expandCall(job)\n",
    "        out.append(out_)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandCall(kargs):\n",
    "    # Expand the arguments of a callback function, kargs['func']\n",
    "    func=kargs['func']\n",
    "    del kargs['func']\n",
    "    out=func(**kargs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target series\n",
    "ptsl = [1,1]\n",
    "target = dailyVol\n",
    "# select minRet\n",
    "minRet = 0.01\n",
    "\n",
    "# Run in single-threaded mode on Windows\n",
    "import platform\n",
    "if platform.system() == \"Windows\":\n",
    "    cpus = 1\n",
    "else:\n",
    "    cpus = cpu_count() - 1\n",
    "    \n",
    "events = getEvents(close,tEvents,ptsl,target,minRet,cpus,t1=t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBins(events, close):\n",
    "    '''\n",
    "    Compute event's outcome (including side information, if provided).\n",
    "    events is a DataFrame where:\n",
    "    -events.index is event's starttime\n",
    "    -events['t1'] is event's endtime\n",
    "    -events['trgt'] is event's target\n",
    "    -events['side'] (optional) implies the algo's position side\n",
    "    Case 1: ('side' not in events): bin in (-1,1) <-label by price action\n",
    "    Case 2: ('side' in events): bin in (0,1) <-label by pnl (meta-labeling)\n",
    "    '''\n",
    "    #1) prices aligned with events\n",
    "    events_=events.dropna(subset=['t1'])\n",
    "    px=events_.index.union(events_['t1'].values).drop_duplicates()\n",
    "    px=close.reindex(px,method='bfill')\n",
    "    #2) create out object\n",
    "    out=pd.DataFrame(index=events_.index)\n",
    "    out['ret']=px.loc[events_['t1'].values].values/px.loc[events_.index]-1\n",
    "    if 'side' in events_:out['ret']*=events_['side'] # meta-labeling\n",
    "    out['bin']=np.sign(out['ret'])\n",
    "    if 'side' in events_:out.loc[out['ret']<=0,'bin']=0 # meta-labeling\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getBins(events, close)\n",
    "print(labels.bin.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropLabels(events, minPct=.05):\n",
    "    # apply weights, drop labels with insufficient examples\n",
    "    while True:\n",
    "        df0=events['bin'].value_counts(normalize=True)\n",
    "        if df0.min()>minPct or df0.shape[0]<3:break\n",
    "        print('dropped label: ', df0.argmin(),df0.min())\n",
    "        events=events[events['bin']!=df0.argmin()]\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_labels = dropLabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_labels.bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinsNew(events, close, t1=None):\n",
    "    '''\n",
    "    Compute event's outcome (including side information, if provided).\n",
    "    events is a DataFrame where:\n",
    "    -events.index is event's starttime\n",
    "    -events['t1'] is event's endtime\n",
    "    -events['trgt'] is event's target\n",
    "    -events['side'] (optional) implies the algo's position side\n",
    "    -t1 is original vertical barrier series\n",
    "    Case 1: ('side' not in events): bin in (-1,1) <-label by price action\n",
    "    Case 2: ('side' in events): bin in (0,1) <-label by pnl (meta-labeling)\n",
    "    '''\n",
    "    #1) prices aligned with events\n",
    "    events_=events.dropna(subset=['t1'])\n",
    "    px=events_.index.union(events_['t1'].values).drop_duplicates()\n",
    "    px=close.reindex(px,method='bfill')\n",
    "    #2) create out object\n",
    "    out=pd.DataFrame(index=events_.index)\n",
    "    out['ret']=px.loc[events_['t1'].values].values/px.loc[events_.index]-1\n",
    "    if 'side' in events_:out['ret']*=events_['side'] # meta-labeling\n",
    "    out['bin']=np.sign(out['ret'])\n",
    "    \n",
    "    if 'side' not in events_:\n",
    "        # only applies when not meta-labeling\n",
    "        # to update bin to 0 when vertical barrier is touched, we need the original\n",
    "        # vertical barrier series since the events['t1'] is the time of first \n",
    "        # touch of any barrier and not the vertical barrier specifically. \n",
    "        # The index of the intersection of the vertical barrier values and the \n",
    "        # events['t1'] values indicate which bin labels needs to be turned to 0\n",
    "        vtouch_first_idx = events[events['t1'].isin(t1.values)].index\n",
    "        out.loc[vtouch_first_idx, 'bin'] = 0.\n",
    "    \n",
    "    if 'side' in events_:out.loc[out['ret']<=0,'bin']=0 # meta-labeling\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_window = 3\n",
    "slow_window = 7\n",
    "\n",
    "close_df = (pd.DataFrame()\n",
    "            .assign(price=close)\n",
    "            .assign(fast=close.ewm(fast_window).mean())\n",
    "            .assign(slow=close.ewm(slow_window).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_up_cross(df):\n",
    "    crit1 = df.fast.shift(1) < df.slow.shift(1)\n",
    "    crit2 = df.fast > df.slow\n",
    "    return df.fast[(crit1) & (crit2)]\n",
    "\n",
    "def get_down_cross(df):\n",
    "    crit1 = df.fast.shift(1) > df.slow.shift(1)\n",
    "    crit2 = df.fast < df.slow\n",
    "    return df.fast[(crit1) & (crit2)]\n",
    "\n",
    "up = get_up_cross(close_df)\n",
    "down = get_down_cross(close_df)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(11,8))\n",
    "\n",
    "close_df.loc['2014':].plot(ax=ax, alpha=.5)\n",
    "up.loc['2014':].plot(ax=ax,ls='',marker='^', markersize=7,\n",
    "                     alpha=0.75, label='upcross', color='g')\n",
    "down.loc['2014':].plot(ax=ax,ls='',marker='v', markersize=7, \n",
    "                       alpha=0.75, label='downcross', color='r')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_up = pd.Series(1, index=up.index)\n",
    "side_down = pd.Series(-1, index=down.index)\n",
    "side = pd.concat([side_up,side_down]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minRet = .01 \n",
    "ptsl=[1,2]\n",
    "\n",
    "dailyVol = getDailyVol(close_df['price'])\n",
    "tEvents = getTEvents(close_df['price'],h=dailyVol.mean())\n",
    "t1 = addVerticalBarrier(tEvents, close_df['price'], numDays=1)\n",
    "\n",
    "ma_events = getEvents(close_df['price'],tEvents,ptsl,target,minRet,cpus,\n",
    "                      t1=t1,side=side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_events.side.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_side = ma_events.dropna().side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_bins = getBinsNew(ma_events,close_df['price'], t1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx = pd.merge_asof(ma_bins, side.to_frame().rename(columns={0:'side'}),\n",
    "                   left_index=True, right_index=True, direction='forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ma_side.values.reshape(-1,1)\n",
    "#X = Xx.side.values.reshape(-1,1)\n",
    "y = ma_bins.bin.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,\n",
    "                                                    shuffle=False)\n",
    "\n",
    "n_estimator = 10000\n",
    "rf = RandomForestClassifier(max_depth=2, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=777)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# The random forest model by itself\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbands(price, window=None, width=None, numsd=None):\n",
    "    \"\"\" returns average, upper band, and lower band\"\"\"\n",
    "    ave = price.rolling(window).mean()\n",
    "    sd = price.rolling(window).std(ddof=0)\n",
    "    if width:\n",
    "        upband = ave * (1+width)\n",
    "        dnband = ave * (1-width)\n",
    "        return price, np.round(ave,3), np.round(upband,3), np.round(dnband,3)        \n",
    "    if numsd:\n",
    "        upband = ave + (sd*numsd)\n",
    "        dnband = ave - (sd*numsd)\n",
    "        return price, np.round(ave,3), np.round(upband,3), np.round(dnband,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window=50\n",
    "bb_df = pd.DataFrame()\n",
    "bb_df['price'],bb_df['ave'],bb_df['upper'],bb_df['lower']=bbands(close, window=window, numsd=1)\n",
    "bb_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(11,8))\n",
    "bb_df.loc['2014'].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_up_cross(df, col):\n",
    "    # col is price column\n",
    "    crit1 = df[col].shift(1) < df.upper.shift(1)  \n",
    "    crit2 = df[col] > df.upper\n",
    "    return df[col][(crit1) & (crit2)]\n",
    "\n",
    "def get_down_cross(df, col):\n",
    "    # col is price column    \n",
    "    crit1 = df[col].shift(1) > df.lower.shift(1) \n",
    "    crit2 = df[col] < df.lower\n",
    "    return df[col][(crit1) & (crit2)]\n",
    "\n",
    "bb_down = get_down_cross(bb_df, 'price')\n",
    "bb_up = get_up_cross(bb_df, 'price') \n",
    "\n",
    "f, ax = plt.subplots(figsize=(11,8))\n",
    "\n",
    "bb_df.loc['2014':].plot(ax=ax, alpha=.5)\n",
    "bb_up.loc['2014':].plot(ax=ax, ls='', marker='^', markersize=7,\n",
    "                        alpha=0.75, label='upcross', color='g')\n",
    "bb_down.loc['2014':].plot(ax=ax, ls='', marker='v', markersize=7, \n",
    "                          alpha=0.75, label='downcross', color='r')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_side_up = pd.Series(-1, index=bb_up.index) # sell on up cross for mean reversion\n",
    "bb_side_down = pd.Series(1, index=bb_down.index) # buy on down cross for mean reversion\n",
    "bb_side_raw = pd.concat([bb_side_up,bb_side_down]).sort_index()\n",
    "\n",
    "minRet = .01 \n",
    "ptsl=[0,2]\n",
    "bb_events = getEvents(close,tEvents,ptsl,target,minRet,cpus,t1=t1,side=bb_side_raw)\n",
    "\n",
    "bb_side = bb_events.dropna().side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_side.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_bins = getBins(bb_events,close).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bb_bins.bin.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returns(s):\n",
    "    arr = np.diff(np.log(s))\n",
    "    return (pd.Series(arr, index=s.index[1:]))\n",
    "\n",
    "def df_rolling_autocorr(df, window, lag=1):\n",
    "    \"\"\"Compute rolling column-wise autocorrelation for a DataFrame.\"\"\"\n",
    "\n",
    "    return (df.rolling(window=window)\n",
    "            .corr(df.shift(lag))) # could .dropna() here\n",
    "\n",
    "#df_rolling_autocorr(d1, window=21).dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_corr = df_rolling_autocorr(returns(close), window=window).rename('srl_corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (pd.DataFrame()\n",
    "            .assign(vol=bb_events.trgt)\n",
    "            .assign(ma_side=ma_side)\n",
    "            .assign(srl_corr=srl_corr)\n",
    "            .drop_duplicates()\n",
    "            .dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = (pd.merge_asof(features, bb_bins[['bin']], \n",
    "                    left_index=True, right_index=True, \n",
    "                    direction='forward').dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy.bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy.drop('bin',axis=1).values\n",
    "y = Xy['bin'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,\n",
    "                                                    shuffle=False)\n",
    "\n",
    "n_estimator = 10000\n",
    "rf = RandomForestClassifier(max_depth=2, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=777)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# The random forest model by itself\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "print(classification_report(y_test, y_pred, target_names=['no_trade','trade']))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minRet = .01 \n",
    "ptsl=[0,2]\n",
    "bb_events = getEvents(close,tEvents,ptsl,target,minRet,cpus,t1=t1)\n",
    "\n",
    "bb_bins = getBins(bb_events,close).dropna()\n",
    "\n",
    "features = (pd.DataFrame()\n",
    "            .assign(vol=bb_events.trgt)\n",
    "            .assign(ma_side=ma_side)\n",
    "            .assign(srl_corr=srl_corr)\n",
    "            .drop_duplicates()\n",
    "            .dropna())\n",
    "\n",
    "Xy = (pd.merge_asof(features, bb_bins[['bin']], \n",
    "                    left_index=True, right_index=True, \n",
    "                    direction='forward').dropna())\n",
    "\n",
    "### run model ###\n",
    "X = Xy.drop('bin',axis=1).values\n",
    "y = Xy['bin'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,\n",
    "                                                    shuffle=False)\n",
    "\n",
    "n_estimator = 10000\n",
    "rf = RandomForestClassifier(max_depth=2, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=777)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# The random forest model by itself\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "print(classification_report(y_test, y_pred, \n",
    "                            target_names=['no_trade','trade']))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
